{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a829edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-macos\n",
    "# !pip install git+https://github.com/TahaAnwar/pafy.git#egg=pafy\n",
    "# !pip install --upgrade gcloud\n",
    "# !pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca56b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57ab44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load(\"/Users/jbell/Desktop/SquashVideoAnalysis/movenet_multipose_lightning_1\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5042166",
   "metadata": {},
   "source": [
    "# Draw Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230d47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 3, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17338dc6",
   "metadata": {},
   "source": [
    "# Draw Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25ffbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6680e6",
   "metadata": {},
   "source": [
    "# Draw Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b0a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            lines = cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d96934c",
   "metadata": {},
   "source": [
    "# Loop Through Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50b2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32969e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(keypoints_with_scores[:,])\n",
    "# person[11]  # Left Hip\n",
    "# person[12]  # Right Hip\n",
    "# person[13]  # Left Knee\n",
    "# person[14]  # Right Knee\n",
    "# person[15]  # Left Ankle\n",
    "# person[16]  # Right Ankle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639594c1",
   "metadata": {},
   "source": [
    "# Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c15433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:57:02.328458: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22371083 0.18305889 0.07997732]\n",
      " [0.4452223  0.6800858  0.06159584]\n",
      " [0.0945094  0.66962266 0.05179015]\n",
      " [0.3835691  0.76988494 0.08638731]\n",
      " [0.81532    0.462158   0.04947201]\n",
      " [0.51629895 0.86724806 0.06518994]]\n",
      "[[1.7123595e-01 2.0440145e-01 1.8423235e-01]\n",
      " [4.4162327e-01 7.5894326e-01 4.4878641e-01]\n",
      " [4.5214945e-01 5.5259120e-01 5.7532534e-04]\n",
      " [4.9315834e-01 6.1279994e-01 3.0354995e-04]\n",
      " [4.4068184e-01 7.5758481e-01 3.3381552e-01]\n",
      " [4.4068184e-01 7.5758481e-01 3.3381552e-01]]\n",
      "[[1.7218448e-01 2.0289931e-01 2.8964588e-01]\n",
      " [4.4262937e-01 8.2131588e-01 3.8152707e-01]\n",
      " [4.4262937e-01 8.2131588e-01 3.8152707e-01]\n",
      " [4.5939520e-01 5.3505737e-01 2.1524802e-03]\n",
      " [2.9855585e-01 1.6218352e-01 8.1867818e-04]\n",
      " [1.7218448e-01 2.0289931e-01 2.8964588e-01]]\n",
      "[[0.17430523 0.20787206 0.30421585]\n",
      " [0.43432847 0.8301889  0.33039558]\n",
      " [0.44012246 0.827596   0.15352096]\n",
      " [0.43249235 0.5691902  0.00925692]\n",
      " [0.17430523 0.20787206 0.30421585]\n",
      " [0.50451255 0.83699125 0.1490402 ]]\n",
      "[[0.16951792 0.20279932 0.27540445]\n",
      " [0.44223964 0.8264121  0.38742968]\n",
      " [0.44038588 0.82565594 0.21344554]\n",
      " [0.45383924 0.5850651  0.00279411]\n",
      " [0.46443462 0.82984376 0.25911513]\n",
      " [0.1644572  0.2031567  0.28433743]]\n",
      "[[1.68871775e-01 2.07521468e-01 2.63987243e-01]\n",
      " [4.32120651e-01 7.98268616e-01 3.77188146e-01]\n",
      " [4.49136049e-01 7.93141901e-01 1.76832587e-01]\n",
      " [4.72906917e-01 5.97550511e-01 1.35096756e-03]\n",
      " [4.59455013e-01 6.65713608e-01 1.02909566e-04]\n",
      " [1.63901001e-01 2.07432911e-01 2.76865304e-01]]\n",
      "[[1.7438988e-01 2.0961849e-01 2.9259229e-01]\n",
      " [4.6178141e-01 7.2326475e-01 6.5165591e-01]\n",
      " [5.0300992e-01 5.7000214e-01 1.2176924e-04]\n",
      " [8.7242514e-01 5.1737207e-01 6.5177055e-03]\n",
      " [1.7438988e-01 2.0961849e-01 2.9259229e-01]\n",
      " [1.7438988e-01 2.0961849e-01 2.9259229e-01]]\n",
      "[[1.7373842e-01 2.0353378e-01 2.4734484e-01]\n",
      " [4.6772233e-01 6.9947845e-01 7.1468431e-01]\n",
      " [5.0234956e-01 6.1242235e-01 2.5748269e-04]\n",
      " [4.6772233e-01 6.9947845e-01 7.1468431e-01]\n",
      " [4.6772233e-01 6.9947845e-01 7.1468431e-01]\n",
      " [7.5773168e-01 7.4133104e-01 1.3114859e-03]]\n",
      "[[1.7182301e-01 2.0363033e-01 3.0058733e-01]\n",
      " [4.7011730e-01 6.9010311e-01 7.3248434e-01]\n",
      " [4.7011730e-01 6.9010311e-01 7.3248434e-01]\n",
      " [4.9028879e-01 6.0741615e-01 1.7995753e-04]\n",
      " [4.6987084e-01 6.8985754e-01 4.7557765e-01]\n",
      " [9.0039390e-01 5.0011575e-01 1.0115009e-02]]\n",
      "[[1.7152384e-01 2.0399308e-01 2.9184213e-01]\n",
      " [4.6181440e-01 6.8128258e-01 6.1642730e-01]\n",
      " [4.6224588e-01 6.8189049e-01 6.2447655e-01]\n",
      " [4.7549397e-01 6.3327199e-01 3.1681839e-04]\n",
      " [7.7925259e-01 7.4074358e-01 1.8365695e-03]\n",
      " [1.7183369e-01 2.0755269e-01 2.8091660e-01]]\n",
      "[[1.6986652e-01 2.0819876e-01 2.7631545e-01]\n",
      " [4.6561643e-01 6.7550206e-01 7.0420915e-01]\n",
      " [4.6561643e-01 6.7550206e-01 7.0420915e-01]\n",
      " [4.7680807e-01 6.2565702e-01 2.0962786e-04]\n",
      " [2.5370592e-01 1.6730538e-01 2.5943613e-03]\n",
      " [1.6986652e-01 2.0819876e-01 2.7631545e-01]]\n",
      "[[1.7235985e-01 2.0762524e-01 2.3494682e-01]\n",
      " [4.7111788e-01 6.6726047e-01 6.5928495e-01]\n",
      " [4.7111788e-01 6.6726047e-01 6.5928495e-01]\n",
      " [4.7585842e-01 6.2719017e-01 2.0576904e-04]\n",
      " [7.9645234e-01 7.2224712e-01 1.9459932e-03]\n",
      " [1.7235985e-01 2.0762524e-01 2.3494682e-01]]\n",
      "[[0.17151795 0.20783173 0.1801755 ]\n",
      " [0.4811255  0.66711885 0.6818052 ]\n",
      " [0.4811255  0.66711885 0.6818052 ]\n",
      " [0.48187208 0.6663122  0.12713079]\n",
      " [0.87091094 0.5039669  0.00605488]\n",
      " [0.76776856 0.22045705 0.01364629]]\n",
      "[[0.17209692 0.209217   0.20204228]\n",
      " [0.4886066  0.66669095 0.6317049 ]\n",
      " [0.4888463  0.66639006 0.60262305]\n",
      " [0.4891161  0.6656012  0.14664117]\n",
      " [0.8970315  0.46998885 0.00591467]\n",
      " [0.8842531  0.47842473 0.00385934]]\n",
      "[[0.17150608 0.20816448 0.29557356]\n",
      " [0.4923755  0.6643569  0.207327  ]\n",
      " [0.4926986  0.6659083  0.7108454 ]\n",
      " [0.4926986  0.6659083  0.7108454 ]\n",
      " [0.15406258 0.2078177  0.11320725]\n",
      " [0.6089774  0.18837628 0.00553235]]\n",
      "[[1.7417873e-01 2.0865950e-01 2.3347808e-01]\n",
      " [5.0354367e-01 6.5692651e-01 5.4299384e-01]\n",
      " [5.0521630e-01 6.5713084e-01 6.4720058e-01]\n",
      " [5.0446361e-01 6.5300930e-01 1.0474125e-01]\n",
      " [4.2208692e-01 4.1467810e-01 3.4873543e-04]\n",
      " [7.8992575e-01 7.3227441e-01 7.8860921e-04]]\n",
      "[[0.17547627 0.20827152 0.24422213]\n",
      " [0.51577777 0.64898866 0.6587856 ]\n",
      " [0.51502556 0.64890933 0.5812999 ]\n",
      " [0.5172536  0.647774   0.31340814]\n",
      " [0.8317469  0.7352464  0.00573447]\n",
      " [0.2941976  0.14985971 0.00192638]]\n",
      "[[1.7139772e-01 2.0382729e-01 2.6635581e-01]\n",
      " [5.3095317e-01 6.4571601e-01 6.7065108e-01]\n",
      " [5.3067011e-01 6.4733964e-01 5.0220877e-01]\n",
      " [5.3243405e-01 6.4382380e-01 2.0120801e-01]\n",
      " [4.5856959e-01 3.8101396e-01 5.2385218e-04]\n",
      " [8.2783675e-01 7.5132138e-01 2.3319220e-02]]\n",
      "[[0.18517065 0.2087981  0.14979273]\n",
      " [0.5404696  0.6469849  0.5954175 ]\n",
      " [0.5407516  0.6488404  0.550728  ]\n",
      " [0.5420837  0.64451325 0.13030194]\n",
      " [0.18517065 0.2087981  0.14979273]\n",
      " [0.5404696  0.6469849  0.5954175 ]]\n",
      "[[0.17520998 0.19461854 0.18731207]\n",
      " [0.5340873  0.6495479  0.65604407]\n",
      " [0.5340873  0.6495479  0.65604407]\n",
      " [0.53301257 0.6461572  0.40858746]\n",
      " [0.17520998 0.19461854 0.18731207]\n",
      " [0.01010592 0.0023757  0.        ]]\n",
      "[[0.17524749 0.21244077 0.16701189]\n",
      " [0.5203173  0.64361966 0.6427667 ]\n",
      " [0.5203173  0.64361966 0.6427667 ]\n",
      " [0.52072644 0.640067   0.2980549 ]\n",
      " [0.17524749 0.21244077 0.16701189]\n",
      " [0.00996649 0.00264988 0.        ]]\n",
      "[[1.8316764e-01 2.1155028e-01 1.4357324e-01]\n",
      " [5.1502866e-01 6.4136386e-01 5.3612810e-01]\n",
      " [5.1623762e-01 6.4181960e-01 6.4116406e-01]\n",
      " [5.1340389e-01 6.3898188e-01 9.2367157e-02]\n",
      " [4.3829104e-01 3.6490795e-01 4.9805042e-04]\n",
      " [1.7713390e-01 2.1160565e-01 1.4050481e-01]]\n",
      "[[0.17344196 0.20894629 0.20611516]\n",
      " [0.5053642  0.6518275  0.719635  ]\n",
      " [0.5053642  0.6518275  0.719635  ]\n",
      " [0.50477326 0.64821464 0.29693186]\n",
      " [0.84636396 0.72250575 0.00760828]\n",
      " [0.17344196 0.20894629 0.20611516]]\n",
      "[[0.17403026 0.21036486 0.21553935]\n",
      " [0.5003444  0.66437036 0.60050714]\n",
      " [0.50205016 0.6648637  0.6371824 ]\n",
      " [0.50132036 0.6625518  0.08204666]\n",
      " [0.17446828 0.20674352 0.15058053]\n",
      " [0.17403026 0.21036486 0.21553935]]\n",
      "[[1.7524739e-01 2.0282435e-01 1.9191991e-01]\n",
      " [4.9437991e-01 6.7076391e-01 5.5421162e-01]\n",
      " [4.9397904e-01 6.7018336e-01 2.7060255e-01]\n",
      " [4.9503422e-01 6.7150688e-01 5.8641374e-01]\n",
      " [4.8982280e-01 3.9101613e-01 5.2988582e-04]\n",
      " [1.7524739e-01 2.0282435e-01 1.9191991e-01]]\n",
      "[[0.17296286 0.19613765 0.18334219]\n",
      " [0.49582905 0.67574507 0.6665111 ]\n",
      " [0.49640137 0.67456675 0.15447249]\n",
      " [0.49582905 0.67574507 0.6665111 ]\n",
      " [0.4980389  0.674663   0.31903762]\n",
      " [0.8482078  0.7337094  0.004065  ]]\n",
      "[[0.1621024  0.20381287 0.2655142 ]\n",
      " [0.50684834 0.6812752  0.6463763 ]\n",
      " [0.5057834  0.68019927 0.28162503]\n",
      " [0.5064254  0.6808777  0.56533   ]\n",
      " [0.86853    0.4828475  0.0035584 ]\n",
      " [0.1621024  0.20381287 0.2655142 ]]\n",
      "[[0.15757094 0.2019593  0.26049697]\n",
      " [0.523025   0.6886253  0.69274956]\n",
      " [0.51975787 0.68693537 0.11133124]\n",
      " [0.523025   0.6886253  0.69274956]\n",
      " [0.5217293  0.6883711  0.6140147 ]\n",
      " [0.8504736  0.7432731  0.00517455]]\n",
      "[[0.1623747  0.20396616 0.25100335]\n",
      " [0.5231253  0.6896081  0.69184107]\n",
      " [0.5146704  0.6860806  0.10448614]\n",
      " [0.521618   0.68901664 0.57131433]\n",
      " [0.85208935 0.74300194 0.00512518]\n",
      " [0.1623747  0.20396616 0.25100335]]\n",
      "[[0.1629432  0.20297344 0.27865118]\n",
      " [0.48323032 0.6674564  0.00187831]\n",
      " [0.50893706 0.68525326 0.69413626]\n",
      " [0.50893706 0.68525326 0.69413626]\n",
      " [0.8665558  0.4453038  0.00339083]\n",
      " [0.85378444 0.48245764 0.00468903]]\n",
      "[[0.1600903  0.20111962 0.22420812]\n",
      " [0.502038   0.6776762  0.55157495]\n",
      " [0.50634456 0.67695814 0.39770445]\n",
      " [0.50465894 0.6772865  0.5831229 ]\n",
      " [0.50465894 0.6772865  0.5831229 ]\n",
      " [0.50465894 0.6772865  0.5831229 ]]\n",
      "[[0.16405451 0.20754738 0.290492  ]\n",
      " [0.5068923  0.6775538  0.577184  ]\n",
      " [0.5079769  0.67760193 0.3243282 ]\n",
      " [0.5068923  0.6775538  0.577184  ]\n",
      " [0.5068923  0.6775538  0.577184  ]\n",
      " [0.8825448  0.45001253 0.00486449]]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 288,512)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "        # Detection section\n",
    "        results = movenet(input_img)\n",
    "        keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "        print(keypoints_with_scores[:,0])\n",
    "    \n",
    "        # Render keypoints \n",
    "        loop_through_people(frame, keypoints_with_scores, EDGES, 0.25)\n",
    "    \n",
    "        cv2.imshow('Movenet Multipose', frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "232f4ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'try' statement on line 6 (2354694882.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(lst)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 6\n"
     ]
    }
   ],
   "source": [
    "def calculate_distance(frame, keypoints):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    lst.append(shaped[0])\n",
    "    try:\n",
    "#             print(keypoints_with_scores[:,0,0][i] - keypoints_with_scores[:,0,0][i - 1])\n",
    "#     except:\n",
    "#         pass\n",
    "#     print(\"----\")\n",
    "#     for i in range(len(keypoints_with_scores[:,0,0])):\n",
    "#         print(keypoints_with_scores[:,0,0][i])\n",
    "    print(lst)\n",
    "#     print(keypoints[0])\n",
    "#     print(shaped[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c25beb",
   "metadata": {},
   "source": [
    "# Class for Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "405a4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    def __init__(self, prev_x = 0, prev_y = 0, curr_x = 0, curr_y = 0, conf = 0):\n",
    "        self.prev_x = prev_x\n",
    "        self.prev_y = prev_y\n",
    "        self.curr_x = curr_x\n",
    "        self.curr_y = curr_y\n",
    "        self.conf = conf\n",
    "        self.distance = 0\n",
    "        \n",
    "    \n",
    "    def draw_keypoints(self, frame, keypoints, confidence_threshold):\n",
    "        y, x, c = frame.shape\n",
    "        shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "        \n",
    "        for kp in shaped:\n",
    "            ky, kx, kp_conf = kp\n",
    "            if kp_conf > confidence_threshold:\n",
    "                cv2.circle(frame, (int(kx), int(ky)), 3, (0,255,0), -1)\n",
    "#             print(\"kx: \", kx)\n",
    "         \n",
    "    def draw_connections(self, frame, keypoints, edges, confidence_threshold):\n",
    "        y, x, c = frame.shape\n",
    "        shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "\n",
    "        for edge, color in edges.items():\n",
    "            p1, p2 = edge\n",
    "            y1, x1, c1 = shaped[p1]\n",
    "            y2, x2, c2 = shaped[p2]\n",
    "\n",
    "            if (c1 > confidence_threshold) & (c2 > confidence_threshold):\n",
    "                    lines = cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 1)\n",
    "                \n",
    "    def calculate_distance(self, frame, keypoints, confidence_threshold):\n",
    "        y, x, c = frame.shape\n",
    "        shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "        \n",
    "        for kp in shaped:\n",
    "            ky, kx, kp_conf = kp\n",
    "            self.conf = kp_conf\n",
    "            \n",
    "            if self.prev_x == 0:\n",
    "                self.prev_x = kx\n",
    "                self.prev_y = ky\n",
    "            else:\n",
    "                self.curr_x = kx\n",
    "                self.curr_y = ky\n",
    "            \n",
    "                # calculate distance\n",
    "\n",
    "                if kp_conf >= confidence_threshold:\n",
    "                    try:\n",
    "                        d_sqr = (self.curr_x - self.prev_x)**2 + (self.curr_y - self.prev_y)**2\n",
    "                        self.distance += math.sqrt(d_sqr)\n",
    "                    except:\n",
    "                        pass\n",
    "                self.prev_x = self.curr_x\n",
    "                self.prev_y = self.curr_y\n",
    "                \n",
    "#             cv2.putText(frame, str('HERE'), (int(self.curr_x),int(self.curr_y)), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 1)\n",
    "\n",
    "    def put_text(self, image, confidence_threshold):\n",
    "        if self.\n",
    "            try:\n",
    "    #             cv2.putText(frame, str(self.distance), (int(shaped[16][1]), int(shaped[16][0])), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 1)\n",
    "                cv2.putText(image, str(self.distance), (int(self.curr_x), int(self.curr_y)), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    #                 cv2.putText(image, str(self.distance), (int(self.curr_x), int(self.curr_y)), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a5d6e",
   "metadata": {},
   "source": [
    "# Run Camera Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed112f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = Person()\n",
    "cap = cv2.VideoCapture('watermarked_preview.mp4')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 288,512)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "        # Detection section\n",
    "        results = movenet(input_img)\n",
    "        keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "    \n",
    "        # Render keypoints \n",
    "        for person in keypoints_with_scores:\n",
    "            per.draw_keypoints(frame, person, 0.05)\n",
    "            per.draw_connections(frame, person, EDGES, 0.05)\n",
    "            per.calculate_distance(frame, person, .6)\n",
    "            per.put_text(frame, .6)\n",
    "    \n",
    "        cv2.imshow('Movenet Multipose', frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "994b1fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Test:   \n",
    "    def __init__(self, distance, ylst = [], xlst = []):\n",
    "        self.distance = distance\n",
    "        self.xlst = xlst\n",
    "        self.ylst = ylst\n",
    "        \n",
    "    def calculate_distance(self, a, b):\n",
    "        self.distance = a + 1\n",
    "#         self.xlst.append(a)\n",
    "        return self.distance, self.xlst\n",
    "\n",
    "ex = Test(0)\n",
    "\n",
    "# print(ex.xlst)\n",
    "ex.calculate_distance(2, 7)\n",
    "ex.distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
